# 联邦学习 通信挑战

### 导言

随着移动互联网的普及和智能设备的迅速发展，**联邦学习（Federated Learning）** 作为一种分布式机器学习框架，逐渐成为解决数据隐私和通信效率问题的关键技术。与传统的集中式机器学习方法不同，联邦学习允许 **多个设备（如手机、物联网设备）在本地存储和处理数据**，而不是将数据上传到云端进行集中式训练。这种方式能够有效保护用户隐私，因为数据始终保留在本地设备上，避免了敏感信息的泄露。然而，联邦学习面临着一系列独特的挑战，其中 **通信效率** 是最为突出的一个问题。

在联邦学习中，客户端设备需要根据本地数据计算模型更新，并将这些更新传输到中央服务器进行聚合。这种 **客户端到服务器的频繁通信** 成为制约系统性能的瓶颈，尤其是在 **设备数量众多、网络连接不稳定或带宽有限的情况下**。每轮训练中，客户端需要传输的模型更新往往是高维的，且训练数据量和参与设备的规模都在不断增加，导致通信开销急剧上升。因此，如何优化联邦学习中的通信过程，减少每轮通信的数据量，成为实现高效、可扩展联邦学习系统的关键。

为了应对这一挑战，研究者们提出了多种策略来 **减轻通信负担**，如 **压缩模型更新**、**低秩表示** 或 **结构化更新**，这些方法通过减少传输的数据量来提高通信效率。尽管这些方法在一定程度上取得了成功，但如何在保证模型性能的同时，进一步优化通信过程，仍然是一个亟待解决的课题。本篇论文旨在探讨当前联邦学习中通信面临的主要挑战，并提出一系列创新性的解决方案，以期在 **隐私保护** 和 **通信效率** 之间实现更好的平衡。

## 问题

### 同步与节点参与度不均问题：
联邦学习的全局模型更新参数会把一个周期内的局部模型的传递值采集完成才能进行更新。可以打破周期更新的局限性。局部模型参数可以随时上传，靠权重更新（异步通信）；

## 论文 

### [Federated Learning with Quantized Models](https://arxiv.org/abs/2003.03827)
该论文介绍了传递$H_t^{i}$的压缩方法: __Structured updates__ 和 __Sketched updates__ 

#### __Structured updates__
- 低秩矩阵: 限制$rank(H_t^{i}) ≤ k$
  $H_t^{i}= \mathbb{R}^{d_1 \times k}\cdot \mathbb{R}^{k \times d_2}$
- 随机掩码: 通过seed生成掩码矩阵，传输只用传递seed和非零值

#### __Sketched updates__
有损压缩
- 子采样: 与随机掩码类似，不同的是可能会发送0值
- 数据离散化: 
  这种方法可以把连续的数据划分到$2^{\mathbb{b}}$个离散值上，把数据用$\mathbb{b}$bit即可表示
  $$
  h_j =
  \begin{cases}
  h_{\text{max}}, & \text{with probability } \frac{h_j - h_{\text{min}}}{h_{\text{max}} - h_{\text{min}}} \\
  h_{\text{min}}, & \text{with probability } \frac{h_{\text{max}} - h_j}{h_{\text{max}} - h_{\text{min}}}
  \end{cases}
  $$
  但有局限性: 要求不同维度之间的数据范围大致在同一个数量级内

- 通过引入结构化的随机旋转来改进量化过程:
  通过旋转矩阵$R$,使$h' = Rh$的每个维度的数量级进行规范化。在全局更新阶段，需要进行逆旋转还原。需要注意的是，在实践中，$ h $ 的维度通常可以高达 $ d = 10^6 $ 或更高，而生成（$ O(d^3) $）和应用（$ O(d^2) $）一般的旋转矩阵在计算上是不可行的。与 Suresh 等人（2017）的做法相同，使用一种结构化的旋转矩阵，这种矩阵是 Walsh-Hadamard 矩阵与二进制对角矩阵的乘积。这将生成和应用矩阵的计算复杂度降低到 $ O(d) $ 和 $ O(d \log d) $，相对于联邦学习中的本地训练，这些复杂度是可以忽略不计的。

### [Communication-Efficient Learning in Federated Learning with Non-IID Data](https://arxiv.org/abs/2006.03899)
